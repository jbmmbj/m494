{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jbmmbj/m494/blob/main/progress%2010-3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install FrEIA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0BLNcs8laMH",
        "outputId": "78f2475a-19b7-4cdb-fcd4-9d7e748f2cac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: FrEIA in /usr/local/lib/python3.10/dist-packages (0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from FrEIA) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from FrEIA) (1.11.3)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from FrEIA) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->FrEIA) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->FrEIA) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->FrEIA) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->FrEIA) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->FrEIA) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->FrEIA) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0.0->FrEIA) (3.27.5)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0.0->FrEIA) (17.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->FrEIA) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->FrEIA) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy"
      ],
      "metadata": {
        "id": "Ipl_gfb4AJvb",
        "outputId": "9a4f9f30-e9a0-4855-c0b4-81236a734098",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas"
      ],
      "metadata": {
        "id": "l6kgb1CiA0Dn",
        "outputId": "b3bcf7c0-ad7e-4890-a263-0a108766df70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lHoAkmetj03J"
      },
      "outputs": [],
      "source": [
        "# standard imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "# FrEIA imports\n",
        "import FrEIA.framework as Ff\n",
        "import FrEIA.modules as Fm\n",
        "\n",
        "BATCHSIZE = 100\n",
        "N_DIM = 2\n",
        "\n",
        "# we define a subnet for use inside an affine coupling block\n",
        "# for more detailed information see the full tutorial\n",
        "def subnet_fc(dims_in, dims_out):\n",
        "    return nn.Sequential(nn.Linear(dims_in, 512), nn.ReLU(),\n",
        "                         nn.Linear(512,  dims_out))\n",
        "\n",
        "# a simple chain of operations is collected by ReversibleSequential\n",
        "inn = Ff.SequenceINN(N_DIM)\n",
        "for k in range(8):\n",
        "    inn.append(Fm.AllInOneBlock, subnet_constructor=subnet_fc, permute_soft=True)\n",
        "\n",
        "optimizer = torch.optim.Adam(inn.parameters(), lr=0.001)\n",
        "\n",
        "# a very basic training loop\n",
        "for i in range(1000):\n",
        "    optimizer.zero_grad()\n",
        "    # sample data from the moons distribution\n",
        "    data, label = make_moons(n_samples=BATCHSIZE, noise=0.05)\n",
        "    x = torch.Tensor(data)\n",
        "    # pass to INN and get transformed variable z and log Jacobian determinant\n",
        "    z, log_jac_det = inn(x)\n",
        "    # calculate the negative log-likelihood of the model with a standard normal prior\n",
        "    loss = 0.5*torch.sum(z**2, 1) - log_jac_det\n",
        "    loss = loss.mean() / N_DIM\n",
        "    # backpropagate and update the weights\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# sample from the INN by sampling from a standard normal and transforming\n",
        "# it in the reverse direction\n",
        "z = torch.randn(BATCHSIZE, N_DIM)\n",
        "samples, _ = inn(z, rev=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "# Load data from https://www.openml.org/d/554\n",
        "x, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
      ],
      "metadata": {
        "id": "iBBKH-oqmZCJ",
        "outputId": "41afea10-220e-4e45-a109-7cc5c0d4a9da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N4jv_mo63yAQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape\n",
        "type(x)\n",
        "type(data)\n",
        "x = x.to_numpy()\n",
        "x = torch.Tensor(x)\n",
        "x.shape"
      ],
      "metadata": {
        "id": "nb7yeVWc35jP",
        "outputId": "717eac16-a747-4794-97cd-dc1278e4100a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([70000, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import FrEIA.framework as Ff\n",
        "import FrEIA.modules as Fm\n",
        "\n",
        "def subnet_fc(dims_in, dims_out):\n",
        "    '''Return a feed-forward subnetwork, to be used in the coupling blocks below'''\n",
        "    return nn.Sequential(nn.Linear(dims_in, 128), nn.ReLU(),\n",
        "                         nn.Linear(128,  128), nn.ReLU(),\n",
        "                         nn.Linear(128,  dims_out))\n",
        "\n",
        "# a tuple of the input data dimension. 784 is the dimension of flattened MNIST images.\n",
        "# (input_dims would be (3, 32, 32) for CIFAR for instance)\n",
        "input_dims = (784,)\n",
        "\n",
        "# construct the INN (not containing any operations so far)\n",
        "inn = Ff.SequenceINN(*input_dims)\n",
        "\n",
        "# append coupling blocks to the sequence of operations\n",
        "for k in range(8):\n",
        "    inn.append(Fm.AllInOneBlock, subnet_constructor=subnet_fc)\n",
        "\n",
        "z, jac = inn(x)\n",
        "x_inv, jac_inv = inn(z, rev=True)\n",
        "\n",
        "# inverting from the outputs should give the original inputs again\n",
        "assert torch.max(torch.abs(x - x_inv)) < 1e-5\n",
        "\n",
        "# the inverse log-det-Jacobian should be the negative of the forward log-det-Jacobian\n",
        "assert torch.max(torch.abs(jac + jac_inv)) < 1e-5\n",
        "\n",
        "cond_dims = (10,)\n",
        "\n",
        "# use the input_dims (784,) from above\n",
        "cinn = Ff.SequenceINN(*input_dims)\n",
        "\n",
        "for k in range(8):\n",
        "    # The cond=0 argument tells the operation which of the conditions it should\n",
        "    # use, that are supplied with the call. So cond=0 means 'use the first condition'\n",
        "    # (there is only one condition in this case).\n",
        "    cinn.append(Fm.AllInOneBlock, cond=0, cond_shape=cond_dims, subnet_constructor=subnet_fc)\n",
        "\n",
        "# the conditions have to be given as a list (in this example, a list with\n",
        "# one entry, 'one_hot_labels').  In general, multiple conditions can be\n",
        "# given. The cond argument of the append() method above specifies which\n",
        "# condition is used for each operation.\n",
        "z, jac = cinn(x, c=[one_hot_labels])\n",
        ""
      ],
      "metadata": {
        "id": "iKuw62Im4I3_",
        "outputId": "426728fb-9ce1-42ec-e8ac-a9036f057c1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6fcf9dfbd479>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ]
    }
  ]
}